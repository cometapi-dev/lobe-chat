---
title: Using CometAPI in LobeChat
description: >-
  Learn how to integrate CometAPI's language model APIs into LobeChat. Follow these steps to register, create an API key, configure settings, and start conversations with CometAPI models.

tags:
  - CometAPI
  - AI models
  - API key
  - LLM
  - Web UI
---

# Using CometAPI in LobeChat

<Image alt={'Using CometAPI in LobeChat'} cover src={'https://github.com/lobehub/lobe-chat/assets/example-cometapi-integration.png'} />

[CometAPI](https://api.cometapi.com/) is a unified API platform that provides access to various state-of-the-art language models including GPT-3.5/4, Claude, Llama, and many other cutting-edge models. It offers a simple, OpenAI-compatible interface that makes integration seamless.

This document will guide you on how to use CometAPI in LobeChat:

<Steps>
  ### Step 1: Register and Log in to CometAPI

  - Visit [CometAPI.com](https://api.cometapi.com/) and create an account
  - You can register using your email address
  - After registration, verify your email to activate your account

  <Image alt={'Register CometAPI'} height={457} inStep src={'https://github.com/lobehub/lobe-chat/assets/example-cometapi-register.png'} />

  ### Step 2: Create an API Key

  - Go to the [API Console](https://api.cometapi.com/console/token) or navigate to the API Keys section
  - Click on "Create New Key" to generate a new API key
  - Name your API key appropriately, for example, "LobeChat Integration"
  - Copy the generated API key and store it securely

  <Image alt={'Create CometAPI Key'} height={460} inStep src={'https://github.com/lobehub/lobe-chat/assets/example-cometapi-key.png'} />

  <Callout type={'warning'}>
    Please store the API key securely as it provides access to your CometAPI account. Never share it publicly or commit it to version control.
  </Callout>

  ### Step 3: Check Account Credits

  - Visit your [account dashboard](https://api.cometapi.com/console/account) to check your available credits
  - CometAPI typically provides new users with initial credits for testing
  - You can add more credits as needed based on your usage requirements
  - Different models have different pricing, which you can check in the model documentation

  <Image alt={'CometAPI Credits'} height={385} inStep src={'https://github.com/lobehub/lobe-chat/assets/example-cometapi-credits.png'} />

  ### Step 4: Configure CometAPI in LobeChat

  - Open the `Settings` interface in LobeChat
  - Navigate to `AI Service Provider` section
  - Find and select `CometAPI` from the list of providers
  - Enable CometAPI and enter the API key you obtained in Step 2

  <Image alt={'Configure CometAPI in LobeChat'} height={518} inStep src={'https://github.com/lobehub/lobe-chat/assets/example-cometapi-config.png'} />

  ### Step 5: Select and Use CometAPI Models

  - After configuring the API key, you can select from available CometAPI models
  - Choose a model that suits your needs (e.g., GPT-3.5-turbo for general tasks, GPT-4 for complex reasoning)
  - Start a new conversation or modify an existing assistant to use the selected CometAPI model

  <Image alt={'Use CometAPI model'} height={518} inStep src={'https://github.com/lobehub/lobe-chat/assets/example-cometapi-usage.png'} />

  <Callout type={'info'}>
    CometAPI supports streaming responses for real-time conversations. The integration automatically handles this for a smooth chat experience.
  </Callout>

  <Callout type={'warning'}>
    Usage charges apply based on the models you use and the number of tokens processed. Please refer to CometAPI's pricing documentation for detailed information.
  </Callout>
</Steps>

## Available Models

CometAPI provides access to a wide range of models, including:

- **OpenAI Models**: GPT-3.5-turbo, GPT-4, GPT-4-turbo
- **Anthropic Models**: Claude-3-sonnet, Claude-3-haiku, Claude-3-opus
- **Open Source Models**: Llama-2, Mistral, CodeLlama
- **Specialized Models**: Various fine-tuned models for specific tasks

The exact model availability may vary. Check the CometAPI dashboard for the most up-to-date list of supported models.

## Environment Configuration

For self-hosted LobeChat instances, you can configure CometAPI using environment variables:

```bash
# CometAPI Configuration
COMETAPI_KEY=your_api_key_here
COMETAPI_BASE_URL=https://api.cometapi.com/v1  # Optional: custom endpoint
```

## Troubleshooting

### Common Issues

**Authentication Error (401)**

- Verify that your API key is correctly entered in the settings
- Check that your API key is still valid and hasn't expired
- Ensure your account has sufficient credits

**Model Not Available (404)**

- Verify that the selected model ID exists in CometAPI
- Check if the model requires special permissions or subscriptions

**Rate Limiting (429)**

- CometAPI has rate limits based on your subscription tier
- Consider upgrading your plan if you hit rate limits frequently
- Implement appropriate delays between requests if needed

**Connection Issues**

- Verify your internet connection
- Check if CometAPI services are operational via their status page
- Try switching to a different model if one specific model is having issues

### Debug Mode

For troubleshooting, you can enable debug mode by setting the environment variable:

```bash
DEBUG_COMETAPI_CHAT_COMPLETION=1
```

This will provide detailed logging of API requests and responses.

## Support

- **CometAPI Documentation**: [https://api.cometapi.com/doc](https://api.cometapi.com/doc)
- **CometAPI Support**: Contact through their official support channels
- **LobeChat Issues**: Report integration issues on the [LobeChat GitHub repository](https://github.com/lobehub/lobe-chat/issues)

You can now enjoy conversing with various state-of-the-art language models through CometAPI in LobeChat!
